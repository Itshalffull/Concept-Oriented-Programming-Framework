// Clef Data Integration Kit - Audio/video transcription enricher provider via Whisper
// Sends audio to Whisper API or runs locally, parses timestamped segments.

use std::collections::HashMap;
use std::io::{Read, Write};
use std::net::TcpStream;
use std::process::Command;

pub const PROVIDER_ID: &str = "whisper_transcribe";
pub const PLUGIN_TYPE: &str = "enricher_plugin";

#[derive(Debug, Clone)]
pub struct ContentItem {
    pub id: String,
    pub content: String,
    pub content_type: String,
    pub metadata: Option<HashMap<String, serde_json::Value>>,
}

#[derive(Debug, Clone)]
pub struct EnricherConfig {
    pub model: Option<String>,
    pub api_key: Option<String>,
    pub threshold: Option<f64>,
    pub options: Option<HashMap<String, serde_json::Value>>,
}

#[derive(Debug, Clone)]
pub struct EnrichmentResult {
    pub fields: HashMap<String, serde_json::Value>,
    pub confidence: f64,
    pub metadata: Option<HashMap<String, serde_json::Value>>,
}

#[derive(Debug, Clone)]
pub struct SchemaRef {
    pub name: String,
    pub fields: Option<Vec<String>>,
}

#[derive(Debug, Clone)]
pub struct CostEstimate {
    pub tokens: Option<u64>,
    pub api_calls: Option<u64>,
    pub duration_ms: Option<u64>,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct TranscriptSegment {
    pub text: String,
    pub start: f64,
    pub end: f64,
    pub confidence: f64,
}

#[derive(Debug)]
pub enum EnricherError {
    IoError(std::io::Error),
    ProcessError(String),
    NetworkError(String),
    ParseError(String),
}

impl From<std::io::Error> for EnricherError {
    fn from(e: std::io::Error) -> Self {
        EnricherError::IoError(e)
    }
}

fn parse_whisper_json(json_str: &str) -> Vec<TranscriptSegment> {
    let parsed: serde_json::Value = match serde_json::from_str(json_str) {
        Ok(v) => v,
        Err(_) => return vec![],
    };

    let segments = parsed.get("segments").and_then(|s| s.as_array());
    match segments {
        Some(segs) => segs.iter().filter_map(|seg| {
            let text = seg.get("text").and_then(|t| t.as_str())?.trim().to_string();
            let start = seg.get("start").and_then(|s| s.as_f64()).unwrap_or(0.0);
            let end = seg.get("end").and_then(|e| e.as_f64()).unwrap_or(0.0);
            let no_speech = seg.get("no_speech_prob").and_then(|n| n.as_f64()).unwrap_or(0.0);
            Some(TranscriptSegment {
                text,
                start,
                end,
                confidence: 1.0 - no_speech,
            })
        }).collect(),
        None => vec![],
    }
}

fn parse_srt(srt: &str) -> Vec<TranscriptSegment> {
    let mut segments = Vec::new();

    for block in srt.split("\n\n") {
        let lines: Vec<&str> = block.lines().collect();
        if lines.len() < 3 { continue; }

        // Parse "HH:MM:SS,mmm --> HH:MM:SS,mmm"
        let time_line = lines[1];
        let parts: Vec<&str> = time_line.split(" --> ").collect();
        if parts.len() != 2 { continue; }

        let start = parse_srt_timestamp(parts[0]);
        let end = parse_srt_timestamp(parts[1]);
        let text = lines[2..].join(" ").trim().to_string();

        if !text.is_empty() {
            segments.push(TranscriptSegment { text, start, end, confidence: 0.85 });
        }
    }

    segments
}

fn parse_srt_timestamp(ts: &str) -> f64 {
    let ts = ts.trim();
    let parts: Vec<&str> = ts.split(':').collect();
    if parts.len() != 3 { return 0.0; }
    let hours: f64 = parts[0].parse().unwrap_or(0.0);
    let minutes: f64 = parts[1].parse().unwrap_or(0.0);
    let sec_parts: Vec<&str> = parts[2].split(|c| c == ',' || c == '.').collect();
    let seconds: f64 = sec_parts.get(0).and_then(|s| s.parse().ok()).unwrap_or(0.0);
    let millis: f64 = sec_parts.get(1).and_then(|s| s.parse().ok()).unwrap_or(0.0);
    hours * 3600.0 + minutes * 60.0 + seconds + millis / 1000.0
}

fn transcribe_local(
    audio_path: &str,
    model_size: &str,
    language: &str,
) -> Result<Vec<TranscriptSegment>, EnricherError> {
    let tmp_dir = std::env::temp_dir();
    let output_stem = format!("clef_whisper_{}", std::process::id());
    let output_path = tmp_dir.join(&output_stem);

    let result = Command::new("whisper")
        .args([
            audio_path,
            "--model", model_size,
            "--language", language,
            "--output_format", "json",
            "--output_dir", tmp_dir.to_str().unwrap_or("/tmp"),
        ])
        .output()?;

    if !result.status.success() {
        let stderr = String::from_utf8_lossy(&result.stderr);
        return Err(EnricherError::ProcessError(format!("Whisper failed: {}", stderr)));
    }

    // Read the JSON output file generated by whisper
    let json_path = tmp_dir.join(format!("{}.json",
        std::path::Path::new(audio_path)
            .file_stem()
            .and_then(|s| s.to_str())
            .unwrap_or("output")));

    let json_content = std::fs::read_to_string(&json_path)
        .map_err(|e| EnricherError::IoError(e))?;
    let _ = std::fs::remove_file(&json_path);

    Ok(parse_whisper_json(&json_content))
}

fn transcribe_api(
    audio_b64: &str,
    api_key: &str,
    model: &str,
    language: &str,
) -> Result<Vec<TranscriptSegment>, EnricherError> {
    let audio_bytes = crate::base64_decode_bytes(audio_b64);
    let boundary = format!("----CopfBoundary{}", std::process::id());

    let mut body = Vec::new();

    // model field
    body.extend_from_slice(format!("--{}\r\nContent-Disposition: form-data; name=\"model\"\r\n\r\n{}\r\n", boundary, model).as_bytes());
    // response_format field
    body.extend_from_slice(format!("--{}\r\nContent-Disposition: form-data; name=\"response_format\"\r\n\r\nverbose_json\r\n", boundary).as_bytes());
    // language field
    body.extend_from_slice(format!("--{}\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n{}\r\n", boundary, language).as_bytes());
    // file field
    body.extend_from_slice(format!("--{}\r\nContent-Disposition: form-data; name=\"file\"; filename=\"audio.wav\"\r\nContent-Type: audio/wav\r\n\r\n", boundary).as_bytes());
    body.extend_from_slice(&audio_bytes);
    body.extend_from_slice(format!("\r\n--{}--\r\n", boundary).as_bytes());

    let request = format!(
        "POST /v1/audio/transcriptions HTTP/1.1\r\nHost: api.openai.com\r\nAuthorization: Bearer {}\r\nContent-Type: multipart/form-data; boundary={}\r\nContent-Length: {}\r\n\r\n",
        api_key, boundary, body.len()
    );

    let mut stream = TcpStream::connect("api.openai.com:443")
        .map_err(|e| EnricherError::NetworkError(format!("Connection failed: {}", e)))?;
    stream.write_all(request.as_bytes())?;
    stream.write_all(&body)?;

    let mut response = Vec::new();
    stream.read_to_end(&mut response)?;
    let response_str = String::from_utf8_lossy(&response);
    let body_start = response_str.find("\r\n\r\n").unwrap_or(0) + 4;
    let json_str = &response_str[body_start..];

    let parsed: serde_json::Value = serde_json::from_str(json_str)
        .map_err(|e| EnricherError::ParseError(format!("JSON parse failed: {}", e)))?;

    let segments = parsed.get("segments")
        .and_then(|s| s.as_array())
        .map(|segs| {
            segs.iter().filter_map(|seg| {
                let text = seg.get("text").and_then(|t| t.as_str())?.trim().to_string();
                let start = seg.get("start").and_then(|s| s.as_f64()).unwrap_or(0.0);
                let end = seg.get("end").and_then(|e| e.as_f64()).unwrap_or(0.0);
                let avg_logprob = seg.get("avg_logprob").and_then(|l| l.as_f64()).unwrap_or(-0.3);
                Some(TranscriptSegment {
                    text,
                    start,
                    end,
                    confidence: avg_logprob.exp(),
                })
            }).collect()
        })
        .unwrap_or_default();

    Ok(segments)
}

// Minimal base64 decode helper
fn base64_decode_bytes(input: &str) -> Vec<u8> {
    let table = b"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    let mut output = Vec::new();
    let chars: Vec<u8> = input.bytes().filter(|b| !b.is_ascii_whitespace()).collect();
    for chunk in chars.chunks(4) {
        let mut buf = [0u8; 4];
        let mut count = 0;
        for (i, &byte) in chunk.iter().enumerate() {
            if byte == b'=' { break; }
            if let Some(pos) = table.iter().position(|&c| c == byte) {
                buf[i] = pos as u8;
                count = i + 1;
            }
        }
        if count >= 2 { output.push((buf[0] << 2) | (buf[1] >> 4)); }
        if count >= 3 { output.push((buf[1] << 4) | (buf[2] >> 2)); }
        if count >= 4 { output.push((buf[2] << 6) | buf[3]); }
    }
    output
}

pub struct WhisperTranscribeEnricherProvider;

impl WhisperTranscribeEnricherProvider {
    pub fn new() -> Self {
        Self
    }

    pub fn enrich(
        &self,
        item: &ContentItem,
        config: &EnricherConfig,
    ) -> Result<EnrichmentResult, EnricherError> {
        let opts = config.options.as_ref();
        let model_size = opts
            .and_then(|o| o.get("modelSize"))
            .and_then(|v| v.as_str())
            .unwrap_or("base");
        let language = opts
            .and_then(|o| o.get("language"))
            .and_then(|v| v.as_str())
            .unwrap_or("en");
        let use_api = config.api_key.is_some();

        let segments = if use_api {
            let api_key = config.api_key.as_deref().unwrap_or("");
            let model = config.model.as_deref().unwrap_or("whisper-1");
            transcribe_api(&item.content, api_key, model, language)?
        } else {
            let tmp_path = std::env::temp_dir()
                .join(format!("clef_audio_{}_{}.wav", item.id, std::process::id()));
            let audio_bytes = base64_decode_bytes(&item.content);
            std::fs::write(&tmp_path, &audio_bytes)?;
            let result = transcribe_local(tmp_path.to_str().unwrap_or(""), model_size, language);
            let _ = std::fs::remove_file(&tmp_path);
            result?
        };

        let full_text: String = segments.iter().map(|s| s.text.as_str()).collect::<Vec<_>>().join(" ");
        let avg_confidence = if segments.is_empty() {
            0.0
        } else {
            segments.iter().map(|s| s.confidence).sum::<f64>() / segments.len() as f64
        };
        let total_duration = segments.last().map(|s| s.end).unwrap_or(0.0);
        let word_count = full_text.split_whitespace().count();

        let mut fields = HashMap::new();
        fields.insert("transcript".to_string(), serde_json::json!({
            "text": full_text,
            "segments": segments,
        }));
        fields.insert("word_count".to_string(), serde_json::json!(word_count));
        fields.insert("duration_seconds".to_string(), serde_json::json!(total_duration));

        let mut metadata = HashMap::new();
        metadata.insert("provider".to_string(), serde_json::json!(PROVIDER_ID));
        metadata.insert("modelSize".to_string(), serde_json::json!(model_size));
        metadata.insert("language".to_string(), serde_json::json!(language));
        metadata.insert("segmentCount".to_string(), serde_json::json!(segments.len()));
        metadata.insert("mode".to_string(), serde_json::json!(if use_api { "api" } else { "local" }));

        Ok(EnrichmentResult {
            fields,
            confidence: avg_confidence,
            metadata: Some(metadata),
        })
    }

    pub fn applies_to(&self, schema: &SchemaRef) -> bool {
        let audio_schemas = ["audio", "video", "podcast", "recording", "speech", "media"];
        let name_lower = schema.name.to_lowercase();
        audio_schemas.iter().any(|s| name_lower.contains(s))
    }

    pub fn cost_estimate(&self, item: &ContentItem) -> CostEstimate {
        let size_kb = item.content.len() as f64 * 3.0 / 4.0 / 1024.0;
        let is_compressed = item.content_type.contains("mp3") || item.content_type.contains("ogg");
        let bytes_per_sec = if is_compressed { 2048.0 } else { 16384.0 };
        let estimated_duration_sec = (size_kb * 1024.0) / bytes_per_sec;
        let processing_ms = (estimated_duration_sec * 33.0).max(1000.0);

        CostEstimate {
            tokens: None,
            api_calls: Some(1),
            duration_ms: Some(processing_ms as u64),
        }
    }
}
